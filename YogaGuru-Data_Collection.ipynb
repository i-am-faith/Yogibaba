{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YogaGuru: Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,math\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture the Landmarks from a Image/Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpDraw = mp.solutions.drawing_utils\n",
    "mpPose = mp.solutions.pose\n",
    "pose = mpPose.Pose()\n",
    "#Enter your video location to collect the landmarks\n",
    "cap = cv2.VideoCapture('C:/Users/mi/YogaGuru/Tree/10.jpg')\n",
    "landmark_frames_data=[]\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    if success==True:\n",
    "        h,w,c=img.shape \n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(imgRGB)\n",
    "        landmark_frames_data.append([results.pose_landmarks])\n",
    "    else:\n",
    "        break\n",
    "print(\"All landmarks Captured in landmark_frames_data \")\n",
    "cap.release() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## landmark_frames_data have relative x,y,z cordinate and the visibility of that body landmark predicted bu Mediapipe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "landmark_frames_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## list of attribute for Making Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list=['right_elbow_angle',\n",
    "'right_shoulder_angle',\n",
    "'left_shoulder_angle',\n",
    "'left_elbow_angle',\n",
    "'right_hip_angle',\n",
    "'left_hip_angle',\n",
    "'right_knee_angle',\n",
    "'left_knee_angle',\n",
    "'right_ankle_angle',\n",
    "'left_ankle_angle',\n",
    "'right_shoulder_wrt_nose_angle',\n",
    "'left_shoulder_wrt_nose_angle',\n",
    "'PoseName',\n",
    "'PoseAccurracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Data frame\n",
    "data=pd.DataFrame(columns=column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  getAngle: a  function to find the angle between 3 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getAngle(a, b, c):\n",
    "    ang = math.degrees(math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "    return ang + 360 if ang < 0 else ang\n",
    " \n",
    "# Example:\n",
    "print(getAngle([0.23182656, 0.86334693, 0.00919855, 0.98291081], [0.2782656, 0.668, 0.00919855, 0.98291081], (0, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make_dict: a function that will return a dict with column attribute and the respective value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(data,pose_name):\n",
    "    test=[]\n",
    "    for res in data[0].landmark:\n",
    "        test.append(np.array([res.x,res.y,res.z,res.visibility]))\n",
    "    test1=[]\n",
    "    for res in test:\n",
    "        test1.append([res[0]*w,res[1]*h,res[2],res[3]])\n",
    "\n",
    "    right_elbow_angle=getAngle(test1[16],test1[14],test1[12])\n",
    "    right_shoulder_angle=getAngle(test1[14],test1[12],test1[24])\n",
    "    left_shoulder_angle=getAngle(test1[13],test1[11],test1[23])\n",
    "    left_elbow_angle=getAngle(test1[15],test1[13],test1[11])\n",
    "\n",
    "    right_hip_angle=getAngle(test1[12],test1[24],test1[26])\n",
    "    left_hip_angle=getAngle(test1[11],test1[23],test1[25])\n",
    "    right_knee_angle=getAngle(test1[24],test1[26],test1[28])\n",
    "    left_knee_angle=getAngle(test1[23],test1[25],test1[27])\n",
    "\n",
    "    right_ankle_angle=getAngle(test1[26],test1[28],test1[32])\n",
    "    left_ankle_angle=getAngle(test1[25],test1[27],test1[31])\n",
    "    right_shoulder_wrt_nose_angle=getAngle(test1[0],test1[12],test1[11])\n",
    "    left_shoulder_wrt_nose_angle=getAngle(test1[0],test1[11],test1[12])\n",
    "\n",
    "    angles={'right_elbow_angle':right_elbow_angle,\n",
    "            'right_shoulder_angle':right_shoulder_angle,\n",
    "            'left_shoulder_angle':left_shoulder_angle,\n",
    "            'left_elbow_angle':left_elbow_angle,\n",
    "            'right_hip_angle':right_hip_angle,\n",
    "            'left_hip_angle':left_hip_angle,\n",
    "            'right_knee_angle':right_knee_angle,\n",
    "            'left_knee_angle':left_knee_angle,\n",
    "            'right_ankle_angle':right_ankle_angle,\n",
    "            'left_ankle_angle':left_ankle_angle,\n",
    "            'right_shoulder_wrt_nose_angle':right_shoulder_wrt_nose_angle,\n",
    "            'left_shoulder_wrt_nose_angle':left_shoulder_wrt_nose_angle,\n",
    "            'PoseName':pose_name,\n",
    "            'PoseAccurracy':0}\n",
    "    return angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_angles_dict: a function that will make a list of dict containg the attributes and their values\n",
    "This is required to add data to a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=[]\n",
    "def get_angles_dict(landmark_frames_data,pose_name):\n",
    "    for i in landmark_frames_data:\n",
    "        if i[0]!=None:\n",
    "            m.append(make_dict(i,pose_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_angles_dict(landmark_frames_data,'Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The result of get_angles_dict is stored in a list name 'm'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataframe to store the body joint angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data=data.append(m,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lets Integrate the different function together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Integrating all the function and creating one point of integration\n",
    "def Generate_Data(list_of_resources,pose_name):\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    mpPose = mp.solutions.pose\n",
    "    pose = mpPose.Pose()\n",
    "    landmark_frames_data=[]\n",
    "    for resorce_location in list_of_resources:\n",
    "        cap = cv2.VideoCapture(resorce_location)\n",
    "        while True:\n",
    "            success, img = cap.read()\n",
    "            if success==True:\n",
    "                h,w,c=img.shape \n",
    "                imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                results = pose.process(imgRGB)\n",
    "                landmark_frames_data.append([results.pose_landmarks])\n",
    "            else:\n",
    "                break\n",
    "    print(\"All landmarks Captured in landmark_frames_data \")\n",
    "    cap.release()\n",
    "    \n",
    "    column_list=['right_elbow_angle',\n",
    "                'right_shoulder_angle',\n",
    "                'left_shoulder_angle',\n",
    "                'left_elbow_angle',\n",
    "                'right_hip_angle',\n",
    "                'left_hip_angle',\n",
    "                'right_knee_angle',\n",
    "                'left_knee_angle',\n",
    "                'right_ankle_angle',\n",
    "                'left_ankle_angle',\n",
    "                'right_shoulder_wrt_nose_angle',\n",
    "                'left_shoulder_wrt_nose_angle',\n",
    "                'PoseName',\n",
    "                'PoseAccurracy']\n",
    "    m=[]\n",
    "     \n",
    "    for i in landmark_frames_data:\n",
    "        if i[0]!=None:\n",
    "            m.append(make_dict(i,pose_name))\n",
    "            \n",
    "    data=pd.DataFrame(columns=column_list)        \n",
    "    data=data.append(m,ignore_index=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Generate_Data function to get the Dataframe by passing he location of Video/photos of the Yoga poses\n",
    "Generate_Data function returns a DataFrame and list_of_resources contains the local drive location of Images/Video required to collect the data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_resources=['C:/Users/mi/YogaGuru/Tree/1.jpg','C:/Users/mi/YogaGuru/Tree/10.jpg','C:/Users/mi/YogaGuru/Tree/1.jpg','C:/Users/mi/YogaGuru/Tree/10.jpg','C:/Users/mi/YogaGuru/Tree/1.jpg','C:/Users/mi/YogaGuru/Tree/10.jpg']\n",
    "Generate_Data(list_of_resources,'demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We need some photos/video which shows the correct poses and will consider that as our 100% accuarte data\n",
    "For more Accuracy will consider atleast 10 images from different tutor and will take mean of all the column attribute and assume that as a standard values and this will minimize the errors for the our perfect pose Data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_perfect_res=['C:/Users/mi/YogaGuru/Tree/1.jpg', 'C:/Users/mi/YogaGuru/Tree/2.jpg', 'C:/Users/mi/YogaGuru/Tree/3.jpg', 'C:/Users/mi/YogaGuru/Tree/4.jpg', 'C:/Users/mi/YogaGuru/Tree/5.jpg', 'C:/Users/mi/YogaGuru/Tree/6.jpg', 'C:/Users/mi/YogaGuru/Tree/7.jpg', 'C:/Users/mi/YogaGuru/Tree/8.jpg', 'C:/Users/mi/YogaGuru/Tree/9.png', 'C:/Users/mi/YogaGuru/Tree/10.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummydata=Generate_Data(list_of_perfect_res,'Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To create the datapoints with 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list=list(dummydata.mean())\n",
    "temp_list.insert(-1,'Tree')\n",
    "temp_list[-1]=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummydata.iloc[0]=temp_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is the data points of 100% Accurate yoga pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummydata.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now will compare all other available data points with these points and calculate the accuarcy using our get_error function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(ideal,practice):\n",
    "        temp=[(abs(ideal[i]-practice[i])/ideal[i]) for i in range(12)]\n",
    "       \n",
    "        return 100-(sum(temp)*100/12) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(dummydata)):\n",
    "    dummydata.iloc[i,13]=get_error(list(dummydata.loc[0,:])[:-2],list(dummydata.loc[i,:])[:-2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummydata=dummydata.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummydata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, Start colleting data from Video\n",
    "Note: The Video/Image should contain a tutor/teacher/person if the video/image have no human body visible it will stop taking the landmarks and it will move to next video/image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=Generate_Data(['C:/Users/mi/YogaGuru/Tree/video1.mp4','C:/Users/mi/YogaGuru/Tree/video2.mp4'],'Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=tree.round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter the error in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(tree)):\n",
    "    tree.iloc[i,13]=get_error(list(dummydata.loc[0,:])[:-2],list(tree.loc[i,:])[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the process for other poses and create a big data set to make a good prediction model\n",
    "Try to make the data set less bias by adding Imgages/Video such that the accuracy for each poses lies between 0 to 100.\n",
    "(This dataset have some bias and therfore the results are not that great but you can improve it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PoseLabel'] = data['PoseName'].astype('category').cat.codes\n",
    "X = data.drop(columns=['PoseName', 'PoseLabel'], errors='ignore')\n",
    "y = data['PoseLabel']\n",
    "\n",
    "# Step 2: Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Evaluate the Model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"yoga_pose_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"Model saved as 'yoga_pose_model.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
